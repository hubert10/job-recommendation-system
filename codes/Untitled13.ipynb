{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n",
      "0.19.2\n",
      "1.11.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pandas\n",
    "import numpy\n",
    "print (matplotlib.__version__)\n",
    "print (pandas.__version__)\n",
    "print (numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "#train_data, test_data = cv.train_test_split(df,test_size=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading ratings file:\n",
    "df = pd.read_csv('/home/nadine/Pictures/Memoir/data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = cv.train_test_split(df,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149973, 3), (49991, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>JobId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44596</th>\n",
       "      <td>1756</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33794</th>\n",
       "      <td>865</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185222</th>\n",
       "      <td>2008</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180241</th>\n",
       "      <td>340</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87683</th>\n",
       "      <td>1992</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194412</th>\n",
       "      <td>430</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171536</th>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101496</th>\n",
       "      <td>556</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31160</th>\n",
       "      <td>590</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129765</th>\n",
       "      <td>184</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160518</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101996</th>\n",
       "      <td>513</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76887</th>\n",
       "      <td>1249</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75077</th>\n",
       "      <td>951</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155652</th>\n",
       "      <td>1351</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>884</td>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57853</th>\n",
       "      <td>1922</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182121</th>\n",
       "      <td>2244</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32151</th>\n",
       "      <td>1338</td>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89086</th>\n",
       "      <td>1413</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91136</th>\n",
       "      <td>1051</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14948</th>\n",
       "      <td>2111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193313</th>\n",
       "      <td>2176</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112508</th>\n",
       "      <td>158</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174829</th>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44046</th>\n",
       "      <td>685</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197643</th>\n",
       "      <td>1784</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105914</th>\n",
       "      <td>1115</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85569</th>\n",
       "      <td>146</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54126</th>\n",
       "      <td>607</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146000</th>\n",
       "      <td>1987</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68200</th>\n",
       "      <td>1247</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98083</th>\n",
       "      <td>1993</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60251</th>\n",
       "      <td>911</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79006</th>\n",
       "      <td>1130</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85308</th>\n",
       "      <td>616</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58400</th>\n",
       "      <td>1851</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79981</th>\n",
       "      <td>1113</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38811</th>\n",
       "      <td>1325</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26599</th>\n",
       "      <td>1398</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123630</th>\n",
       "      <td>463</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165634</th>\n",
       "      <td>228</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60529</th>\n",
       "      <td>2226</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128963</th>\n",
       "      <td>1949</td>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169918</th>\n",
       "      <td>2136</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180348</th>\n",
       "      <td>2118</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192849</th>\n",
       "      <td>352</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196009</th>\n",
       "      <td>2478</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158431</th>\n",
       "      <td>379</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>2416</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158354</th>\n",
       "      <td>2185</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157409</th>\n",
       "      <td>381</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76641</th>\n",
       "      <td>1649</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>94</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48943</th>\n",
       "      <td>1682</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84411</th>\n",
       "      <td>1190</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>2458</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153275</th>\n",
       "      <td>2270</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132611</th>\n",
       "      <td>2407</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101274</th>\n",
       "      <td>700</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149973 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserId  JobId  Rating\n",
       "44596     1756     77       4\n",
       "33794      865     93       2\n",
       "185222    2008     54       3\n",
       "180241     340     54       4\n",
       "87683     1992    118       3\n",
       "194412     430    108       4\n",
       "171536      77     63       4\n",
       "101496     556    110       1\n",
       "31160      590     29       4\n",
       "129765     184     73       2\n",
       "160518      29      9       2\n",
       "101996     513    132       3\n",
       "76887     1249     36       5\n",
       "75077      951    141       2\n",
       "155652    1351     43       4\n",
       "2507       884    132       5\n",
       "57853     1922     33       3\n",
       "182121    2244     55       3\n",
       "32151     1338    126       4\n",
       "89086     1413     92       4\n",
       "91136     1051      6       2\n",
       "14948     2111     16       3\n",
       "193313    2176     16       4\n",
       "112508     158    127       3\n",
       "174829       2    133       1\n",
       "44046      685     93       4\n",
       "197643    1784      9       4\n",
       "105914    1115    117       2\n",
       "85569      146     71       3\n",
       "54126      607     21       5\n",
       "...        ...    ...     ...\n",
       "146000    1987     69       2\n",
       "68200     1247     38       4\n",
       "98083     1993    128       2\n",
       "60251      911     58       5\n",
       "79006     1130     63       4\n",
       "85308      616    149       5\n",
       "58400     1851     65       2\n",
       "79981     1113      4       5\n",
       "38811     1325     97       5\n",
       "26599     1398     16       4\n",
       "123630     463     93       4\n",
       "165634     228     36       3\n",
       "60529     2226    109       2\n",
       "128963    1949    143       5\n",
       "169918    2136    138       4\n",
       "180348    2118    109       3\n",
       "192849     352    103       5\n",
       "196009    2478     15       3\n",
       "158431     379     94       5\n",
       "5320      2416     95       3\n",
       "158354    2185     39       4\n",
       "157409     381     31       3\n",
       "76641     1649     34       3\n",
       "21999       94    113       4\n",
       "48943     1682     95       3\n",
       "84411     1190     28       4\n",
       "2945      2458     10       4\n",
       "153275    2270     82       1\n",
       "132611    2407    139       4\n",
       "101274     700    107       5\n",
       "\n",
       "[149973 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference paper: \"Bayesian Probabilistic Matrix Factorization using MCMC\"\n",
    "                 R. Salakhutdinov and A.Mnih.  \n",
    "                 25th International Conference on Machine Learning (ICML-2008) \n",
    "Reference Matlab code: http://www.cs.toronto.edu/~rsalakhu/BPMF.html\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from numpy.linalg import inv, cholesky\n",
    "\n",
    "#from base import Base, DimensionError\n",
    "#from ..util.load_data import load_ml_1m, load_rating_matrix\n",
    "#from ..util.distributions import wishartrand\n",
    "#from ..util.evaluation_metrics import RMSE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Base class of recommendation System\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class NotImplementedError(Exception):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NotImplementedError, self).__init__()\n",
    "\n",
    "\n",
    "class DimensionError(Exception):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DimensionError, self).__init__()\n",
    "\n",
    "\n",
    "class Base(object):\n",
    "\n",
    "    \"\"\"base class of recommendations\"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_errors = []\n",
    "        self.validation_erros = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, iter=1000):\n",
    "        \"\"\"training models\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def suggestions(self, user_id, num=10):\n",
    "        \"\"\"suggest items for given user\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model(self, path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, path):\n",
    "        \"\"\"load saved models\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "#    def __reper__(self):\n",
    "#return self.__class__.__name__()\n",
    "\n",
    "\n",
    "class BayesianMatrixFactorization(Base):\n",
    "\n",
    "    def __init__(self, num_user, num_item, num_feature, train, validation, **params):\n",
    "        super(BayesianMatrixFactorization, self).__init__()\n",
    "\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.num_feature = num_feature\n",
    "        self.train = train\n",
    "        self.validation = validation\n",
    "\n",
    "        self.mean_rating = np.mean(self.train[:, 2])\n",
    "\n",
    "        self.max_rating = params.get('max_rating')\n",
    "        self.min_rating = params.get('min_rating')\n",
    "        if self.max_rating:\n",
    "            self.max_rating = float(self.max_rating)\n",
    "        if self.min_rating:\n",
    "            self.min_rating = float(self.min_rating)\n",
    "\n",
    "        # Hyper Parameter\n",
    "        self.beta = float(params.get('beta', 2.0))\n",
    "        # Inv-Whishart (User features)\n",
    "        self.WI_user = np.eye(num_feature, dtype='float16')\n",
    "        self.beta_user = float(params.get('beta_user', 2.0))\n",
    "        self.df_user = int(params.get('df_user', num_feature))\n",
    "        self.mu_user = np.zeros((num_feature, 1), dtype='float16')\n",
    "\n",
    "        # Inv-Whishart (item features)\n",
    "        self.WI_item = np.eye(num_feature, dtype='float16')\n",
    "        self.beta_item = float(params.get('beta_item', 2.0))\n",
    "        self.df_item = int(params.get('df_item', num_feature))\n",
    "        self.mu_item = np.zeros((num_feature, 1), dtype='float16')\n",
    "\n",
    "        # Latent Variables\n",
    "        self.mu_user = np.zeros((num_feature, 1), dtype='float16')\n",
    "        self.mu_item = np.zeros((num_feature, 1), dtype='float16')\n",
    "\n",
    "        self.alpha_user = np.eye(num_feature, dtype='float16')\n",
    "        self.alpha_item = np.eye(num_feature, dtype='float16')\n",
    "\n",
    "        self.user_features = 0.3 * np.random.rand(num_user, num_feature)\n",
    "        self.item_features = 0.3 * np.random.rand(num_item, num_feature)\n",
    "\n",
    "        self.matrix = load_rating_matrix()\n",
    "\n",
    "    def estimate(self, iterations=100, tolerance=1e-5):\n",
    "        last_rmse = None\n",
    "\n",
    "        # the algorithm will converge, but really slow\n",
    "        # use MF's initialize latent parameter will be better\n",
    "        for iteration in xrange(iterations):\n",
    "            # update item & user parameter\n",
    "            self._update_item_params()\n",
    "            self._update_user_params()\n",
    "\n",
    "            # update item & user_features\n",
    "            self._udpate_item_features()\n",
    "            self._update_user_features()\n",
    "\n",
    "            # compute RMSE\n",
    "            # train errors\n",
    "            train_preds = self.predict(self.train)\n",
    "            train_rmse = RMSE(train_preds, np.float16(self.train[:, 2]))\n",
    "\n",
    "            # validation errors\n",
    "            validation_preds = self.predict(self.validation)\n",
    "            validation_rmse = RMSE(\n",
    "                validation_preds, np.float16(self.validation[:, 2]))\n",
    "            self.train_errors.append(train_rmse)\n",
    "            self.validation_erros.append(validation_rmse)\n",
    "            print \"iterations: %3d, train RMSE: %.6f, validation RMSE: %.6f \" % (iteration + 1, train_rmse, validation_rmse)\n",
    "\n",
    "            # stop if converge\n",
    "            if last_rmse:\n",
    "                if abs(train_rmse - last_rmse) < tolerance:\n",
    "                    break\n",
    "\n",
    "            last_rmse = train_rmse\n",
    "\n",
    "    def predict(self, data):\n",
    "        u_features = self.user_features[data[:, 0], :]\n",
    "        i_features = self.item_features[data[:, 1], :]\n",
    "        preds = np.sum(u_features * i_features, 1) + self.mean_rating\n",
    "\n",
    "        if self.max_rating:\n",
    "            preds[preds > self.max_rating] = self.max_rating\n",
    "\n",
    "        if self.min_rating:\n",
    "            preds[preds < self.min_rating] = self.min_rating\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def _update_item_params(self):\n",
    "        N = self.num_item\n",
    "        X_bar = np.mean(self.item_features, 0)\n",
    "        X_bar = np.reshape(X_bar, (self.num_feature, 1))\n",
    "        # print 'X_bar', X_bar.shape\n",
    "        S_bar = np.cov(self.item_features.T)\n",
    "        # print 'S_bar', S_bar.shape\n",
    "\n",
    "        norm_X_bar = X_bar - self.mu_item\n",
    "        # print 'norm_X_bar', norm_X_bar.shape\n",
    "\n",
    "        WI_post = self.WI_item + N * S_bar + \\\n",
    "            np.dot(norm_X_bar, norm_X_bar.T) * \\\n",
    "            (N * self.beta_item) / (self.beta_item + N)\n",
    "        # print 'WI_post', WI_post.shape\n",
    "\n",
    "        # Not sure why we need this...\n",
    "        WI_post = (WI_post + WI_post.T) / 2.0\n",
    "        df_post = self.df_item + N\n",
    "\n",
    "        # update alpha_item\n",
    "        self.alpha_item = wishartrand(df_post, WI_post)\n",
    "\n",
    "        # update mu_item\n",
    "        mu_temp = (self.beta_item * self.mu_item + N * X_bar) / \\\n",
    "            (self.beta_item + N)\n",
    "        # print \"mu_temp\", mu_temp.shape\n",
    "        lam = cholesky(inv(np.dot(self.beta_item + N, self.alpha_item)))\n",
    "        # print 'lam', lam.shape\n",
    "        self.mu_item = mu_temp + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "        # print 'mu_item', self.mu_item.shape\n",
    "\n",
    "    def _update_user_params(self):\n",
    "        # same as _update_user_params\n",
    "        N = self.num_user\n",
    "        X_bar = np.mean(self.user_features, 0).T\n",
    "        X_bar = np.reshape(X_bar, (self.num_feature, 1))\n",
    "\n",
    "        # print 'X_bar', X_bar.shape\n",
    "        S_bar = np.cov(self.user_features.T)\n",
    "        # print 'S_bar', S_bar.shape\n",
    "\n",
    "        norm_X_bar = X_bar - self.mu_user\n",
    "        # print 'norm_X_bar', norm_X_bar.shape\n",
    "\n",
    "        WI_post = self.WI_user + N * S_bar + \\\n",
    "            np.dot(norm_X_bar, norm_X_bar.T) * \\\n",
    "            (N * self.beta_user) / (self.beta_user + N)\n",
    "        # print 'WI_post', WI_post.shape\n",
    "\n",
    "        # Not sure why we need this...\n",
    "        WI_post = (WI_post + WI_post.T) / 2.0\n",
    "        df_post = self.df_user + N\n",
    "\n",
    "        # update alpha_user\n",
    "        self.alpha_user = wishartrand(df_post, WI_post)\n",
    "\n",
    "        # update mu_item\n",
    "        mu_temp = (self.beta_user * self.mu_user + N * X_bar) / \\\n",
    "            (self.beta_user + N)\n",
    "        # print 'mu_temp', mu_temp.shape\n",
    "        lam = cholesky(inv(np.dot(self.beta_user + N, self.alpha_user)))\n",
    "        # print 'lam', lam.shape\n",
    "        self.mu_user = mu_temp + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "        # print 'mu_user', self.mu_user.shape\n",
    "\n",
    "    def _udpate_item_features(self):\n",
    "        # Gibbs sampling for item features\n",
    "        for item_id in xrange(self.num_item):\n",
    "            vec = self.matrix[:, item_id] > 0.0\n",
    "            # print 'vec', vec.shape\n",
    "            # if vec.shape[0] == 0:\n",
    "            #    continue\n",
    "            features = self.user_features[vec, :]\n",
    "            # print 'features', features.shape\n",
    "            rating = self.matrix[vec, item_id] - self.mean_rating\n",
    "            rating_len = len(rating)\n",
    "            rating = np.reshape(rating, (rating_len, 1))\n",
    "\n",
    "            # print 'rating', rating.shape\n",
    "            covar = inv(\n",
    "                self.alpha_item + self.beta * np.dot(features.T, features))\n",
    "            # print 'covar', covar.shape\n",
    "            lam = cholesky(covar)\n",
    "\n",
    "            temp = self.beta * \\\n",
    "                np.dot(features.T, rating) + np.dot(\n",
    "                    self.alpha_item, self.mu_item)\n",
    "            # print 'temp', temp.shape\n",
    "            mean = np.dot(covar, temp)\n",
    "            # print 'mean', mean.shape\n",
    "            temp_feature = mean + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "            temp_feature = np.reshape(temp_feature, (self.num_feature,))\n",
    "            self.user_features[item_id, :] = temp_feature\n",
    "\n",
    "    def _update_user_features(self):\n",
    "        self.matrix = self.matrix.T\n",
    "        # Gibbs sampling for user features\n",
    "        for user_id in xrange(self.num_user):\n",
    "            vec = self.matrix[:, user_id] > 0.0\n",
    "            # print len(vec)\n",
    "            # if vec.shape[0] == 0:\n",
    "            #    continue\n",
    "            # print \"item_feature\", self.item_features.shape\n",
    "            features = self.item_features[vec, :]\n",
    "            rating = self.matrix[vec, user_id] - self.mean_rating\n",
    "            rating_len = len(rating)\n",
    "            rating = np.reshape(rating, (rating_len, 1))\n",
    "\n",
    "            # print 'rating', rating.shape\n",
    "            covar = inv(\n",
    "                self.alpha_user + self.beta * np.dot(features.T, features))\n",
    "            lam = cholesky(covar)\n",
    "            temp = self.beta * \\\n",
    "                np.dot(features.T, rating) + np.dot(\n",
    "                    self.alpha_user, self.mu_user)\n",
    "            mean = np.dot(covar, temp)\n",
    "            # print 'mean', mean.shape\n",
    "            temp_feature = mean + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "            temp_feature = np.reshape(temp_feature, (self.num_feature,))\n",
    "            self.user_features[user_id, :] = temp_feature\n",
    "\n",
    "        # transpose back\n",
    "        self.matrix = self.matrix.T\n",
    "\n",
    "    def suggestions(self, user_id, num=10):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def save_model(self):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def load_model(self):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def load_features(self, path):\n",
    "        import cPickle\n",
    "        import gzip\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            self._user_features = cPickle.load(f)\n",
    "            self._item_features = cPickle.load(f)\n",
    "            num_user, num_feature_u = self._user_features.shape\n",
    "            num_item, num_feature_i = self._item_features.shape\n",
    "\n",
    "            if num_feature_i != num_feature_u:\n",
    "                raise DimensionError()\n",
    "            self._num_feature = num_feature_i\n",
    "\n",
    "        return self\n",
    "\n",
    "    def save_features(self, path):\n",
    "        import cPickle\n",
    "        import gzip\n",
    "        with gzip.open(path, 'wb') as f:\n",
    "            cPickle.dump(\n",
    "                self._user_features, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "            cPickle.dump(\n",
    "                self._item_features, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def example():\n",
    "    \"\"\"simple test and performance measure\n",
    "    \"\"\"\n",
    "    num_user, num_item, ratings = load_ml_1m()\n",
    "    # suffle_data\n",
    "    np.random.shuffle(ratings)\n",
    "\n",
    "    # split data to training & validation\n",
    "    train_pct = 0.9\n",
    "    train_size = int(train_pct * len(ratings))\n",
    "    train = ratings[:train_size]\n",
    "    validation = ratings[train_size:]\n",
    "\n",
    "    # params\n",
    "    num_feature = 10\n",
    "    bmf_model = BayesianMatrixFactorization(\n",
    "        num_user, num_item, num_feature, train, validation, max_rating=5, min_rating=1)\n",
    "\n",
    "    start_time = time.clock()\n",
    "    bmf_model.estimate(5)\n",
    "    end_time = time.clock()\n",
    "    print \"time spend = %.3f\" % (end_time - start_time)\n",
    "\n",
    "    return bmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def RMSE(estimation, truth):\n",
    "    \"\"\"Root Mean Square Error\"\"\"\n",
    "\n",
    "    num_sample = len(estimation)\n",
    "\n",
    "    # sum square error \n",
    "    sse = np.sum(np.square(truth - estimation))\n",
    "    return np.sqrt(np.divide(sse, num_sample - 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data set\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "\n",
    "def build_ml_1m():\n",
    "    \"\"\"\n",
    "    build movie lens 1M ratings from original ml_1m rating file.\n",
    "    need to download and put ml_1m data in /data folder first.\n",
    "    Source: http://www.grouplens.org/\n",
    "    \"\"\"\n",
    "    num_user = 6040\n",
    "    num_item = 3952\n",
    "    print(\"\\nloadind movie lens 1M data\")\n",
    "    with open(\"data/ratings.dat\", \"rb\") as f:\n",
    "        iter_lines = iter(f)\n",
    "        ratings = []\n",
    "        for line_num, line in enumerate(iter_lines):\n",
    "            # format (user_id, item_id, rating)\n",
    "            line = line.split('::')[:3]\n",
    "            line = [int(l) for l in line]\n",
    "            ratings.append(line)\n",
    "\n",
    "            if line_num % 100000 == 0:\n",
    "                print line_num\n",
    "\n",
    "    ratings = np.array(ratings)\n",
    "\n",
    "    # shift user_id & movie_id by 1. let user_id & movie_id start from 0\n",
    "    ratings[:, (0, 1)] = ratings[:, (0, 1)] - 1\n",
    "    print \"max user id\", max(ratings[:, 0])\n",
    "    print \"max item id\", max(ratings[:, 1])\n",
    "    return num_user, num_item, ratings\n",
    "\n",
    "\n",
    "def load_ml_1m():\n",
    "    \"\"\"load Movie Lens 1M ratings from saved gzip file\"\"\"\n",
    "    import gzip\n",
    "    import csv\n",
    "    import cPickle\n",
    "\n",
    "    file_path = 'data/data.csv'\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        print \"load ratings from: %s\" % file_path\n",
    "        num_user = cPickle.load(f)\n",
    "        num_item = cPickle.load(f)\n",
    "        ratings = cPickle.load(f)\n",
    "\n",
    "        return num_user, num_item, ratings\n",
    "\n",
    "\n",
    "def build_rating_matrix(num_user, num_item, ratings):\n",
    "    \"\"\"\n",
    "    build dense ratings matrix from original ml_1m rating file.\n",
    "    need to download and put ml_1m data in /data folder first.\n",
    "    Source: http://www.grouplens.org/\n",
    "    \"\"\"\n",
    "\n",
    "    print '\\nbuild matrix'\n",
    "    # sparse matrix\n",
    "    #matrix = sparse.lil_matrix((num_user, num_item))\n",
    "    # dense matrix\n",
    "    matrix = np.zeros((num_user, num_item), dtype='int8')\n",
    "    for item_id in xrange(num_item):\n",
    "        data = ratings[ratings[:, 1] == item_id]\n",
    "        if data.shape[0] > 0:\n",
    "            matrix[data[:, 0], item_id] = data[:, 2]\n",
    "\n",
    "        if item_id % 1000 == 0:\n",
    "            print item_id\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def load_rating_matrix():\n",
    "    \"\"\"\n",
    "    load Movie Lens 1M ratings from saved gzip file\n",
    "    Format is numpy dense matrix\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    import cPickle\n",
    "\n",
    "    file_path = 'data/data.csv'\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        print \"load ratings matrix from: %s\" % file_path\n",
    "        return cPickle.load(f)\n",
    "\n",
    "\n",
    "def build_sparse_matrix(num_user, num_item, ratings):\n",
    "    # TODO: have not tested it yet. will test after algorithm support sparse\n",
    "    # matrix\n",
    "    print '\\nbuild sparse matrix'\n",
    "    # sparse matrix\n",
    "    matrix = sparse.lil_matrix((num_user, num_item))\n",
    "    for item_id in xrange(num_item):\n",
    "        data = ratings[ratings[:, 1] == item_id]\n",
    "        if data.shape[0] > 0:\n",
    "            # for sparse matrix\n",
    "            matrix[data[:, 0], item_id] = np.array([data[:, 2]]).T\n",
    "\n",
    "        if item_id % 1000 == 0:\n",
    "            print item_id\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2da026ceb36e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#    num_user, num_item, ratings = load_ml_1m()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# set feature numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "    # load MovieLens data\n",
    "#    num_user, num_item, ratings = load_ml_1m()\n",
    "    import numpy as np\n",
    "    np.random.shuffle(data_train)\n",
    "\n",
    "    # set feature numbers\n",
    "    num_feature = 10\n",
    "\n",
    "    # set max_iterations\n",
    "    max_iter = 20\n",
    "\n",
    "    # split data to training & testing\n",
    "    train_pct = 0.9\n",
    "    train_size = int(train_pct * len(self.ratings))\n",
    "    train = ratings[:train_size]\n",
    "    validation = ratings[train_size:]\n",
    "\n",
    "    # models\n",
    "    rec = MatrixFactorization(num_user, num_item, num_feature, train, validation, max_rating=5, min_rating=1)\n",
    "\n",
    "    # fitting\n",
    "    rec.estimate(max_iter)\n",
    "\n",
    "    # results\n",
    "    train_preds = rec.predict(train)\n",
    "    train_rmse = RMSE(validation_preds, np.float16(train[:, 2]))\n",
    "    validation_preds = rec.predict(validation)\n",
    "    validation_rmse = RMSE(validation_preds, np.float16(validation[:, 2]))\n",
    "\n",
    "print \"train RMSE: %.6f, validation RMSE: %.6f \" % (train_rmse, validation_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
