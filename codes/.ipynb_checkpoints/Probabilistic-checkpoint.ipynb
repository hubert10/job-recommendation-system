{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: UserId,JobId,Rating",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-097dc434c4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mDATASET\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'real'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-097dc434c4d8>\u001b[0m in \u001b[0;36mreal_ratings\u001b[0;34m(noise)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: UserId,JobId,Rating"
     ]
    }
   ],
   "source": [
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import numpy\n",
    "import pickle\n",
    "\n",
    "class ProbabilisticMatrixFactorization():\n",
    "\n",
    "    def __init__(self, rating_tuples, latent_d=1):\n",
    "        self.latent_d = latent_d\n",
    "        self.learning_rate = .0001\n",
    "        self.regularization_strength = 0.1\n",
    "        \n",
    "        self.ratings = numpy.array(rating_tuples).astype(float)\n",
    "        self.converged = False\n",
    "\n",
    "        self.num_users = int(numpy.max(self.ratings[:, 0]) + 1)\n",
    "        self.num_items = int(numpy.max(self.ratings[:, 1]) + 1)\n",
    "        \n",
    "        print (self.num_users, self.num_items, self.latent_d)\n",
    "        print self.ratings\n",
    "\n",
    "        self.users = numpy.random.random((self.num_users, self.latent_d))\n",
    "        self.items = numpy.random.random((self.num_items, self.latent_d))\n",
    "\n",
    "        self.new_users = numpy.random.random((self.num_users, self.latent_d))\n",
    "        self.new_items = numpy.random.random((self.num_items, self.latent_d))           \n",
    "\n",
    "\n",
    "    def likelihood(self, users=None, items=None):\n",
    "        if users is None:\n",
    "            users = self.users\n",
    "        if items is None:\n",
    "            items = self.items\n",
    "            \n",
    "        sq_error = 0\n",
    "        \n",
    "        for rating_tuple in self.ratings:\n",
    "            if len(rating_tuple) == 3:\n",
    "                (i, j, rating) = rating_tuple\n",
    "                weight = 1\n",
    "            elif len(rating_tuple) == 4:\n",
    "                (i, j, rating, weight) = rating_tuple\n",
    "            \n",
    "            r_hat = numpy.sum(users[i] * items[j])\n",
    "\n",
    "            sq_error += weight * (rating - r_hat)**2\n",
    "\n",
    "        L2_norm = 0\n",
    "        for i in range(self.num_users):\n",
    "            for d in range(self.latent_d):\n",
    "                L2_norm += users[i, d]**2\n",
    "\n",
    "        for i in range(self.num_items):\n",
    "            for d in range(self.latent_d):\n",
    "                L2_norm += items[i, d]**2\n",
    "\n",
    "        return -sq_error - self.regularization_strength * L2_norm\n",
    "        \n",
    "        \n",
    "    def update(self):\n",
    "\n",
    "        updates_o = numpy.zeros((self.num_users, self.latent_d))\n",
    "        updates_d = numpy.zeros((self.num_items, self.latent_d))        \n",
    "\n",
    "        for rating_tuple in self.ratings:\n",
    "            if len(rating_tuple) == 3:\n",
    "                (i, j, rating) = rating_tuple\n",
    "                weight = 1\n",
    "            elif len(rating_tuple) == 4:\n",
    "                (i, j, rating, weight) = rating_tuple\n",
    "            \n",
    "            r_hat = numpy.sum(self.users[i] * self.items[j])\n",
    "            \n",
    "            for d in range(self.latent_d):\n",
    "                updates_o[i, d] += self.items[j, d] * (rating - r_hat) * weight\n",
    "                updates_d[j, d] += self.users[i, d] * (rating - r_hat) * weight\n",
    "\n",
    "        while (not self.converged):\n",
    "            initial_lik = self.likelihood()\n",
    "\n",
    "            print \"  setting learning rate =\", self.learning_rate\n",
    "            self.try_updates(updates_o, updates_d)\n",
    "\n",
    "            final_lik = self.likelihood(self.new_users, self.new_items)\n",
    "\n",
    "            if final_lik > initial_lik:\n",
    "                self.apply_updates(updates_o, updates_d)\n",
    "                self.learning_rate *= 1.25\n",
    "\n",
    "                if final_lik - initial_lik < 10:\n",
    "                    self.converged = True\n",
    "                    \n",
    "                break\n",
    "            else:\n",
    "                self.learning_rate *= .5\n",
    "                self.undo_updates()\n",
    "\n",
    "            if self.learning_rate < 1e-10:\n",
    "                self.converged = True\n",
    "\n",
    "        return not self.converged\n",
    "    \n",
    "\n",
    "    def apply_updates(self, updates_o, updates_d):\n",
    "        for i in range(self.num_users):\n",
    "            for d in range(self.latent_d):\n",
    "                self.users[i, d] = self.new_users[i, d]\n",
    "\n",
    "        for i in range(self.num_items):\n",
    "            for d in range(self.latent_d):\n",
    "                self.items[i, d] = self.new_items[i, d]                \n",
    "\n",
    "    \n",
    "    def try_updates(self, updates_o, updates_d):        \n",
    "        alpha = self.learning_rate\n",
    "        beta = -self.regularization_strength\n",
    "\n",
    "        for i in range(self.num_users):\n",
    "            for d in range(self.latent_d):\n",
    "                self.new_users[i,d] = self.users[i, d] + \\\n",
    "                                       alpha * (beta * self.users[i, d] + updates_o[i, d])\n",
    "        for i in range(self.num_items):\n",
    "            for d in range(self.latent_d):\n",
    "                self.new_items[i, d] = self.items[i, d] + \\\n",
    "                                       alpha * (beta * self.items[i, d] + updates_d[i, d])\n",
    "        \n",
    "\n",
    "    def undo_updates(self):\n",
    "        # Don't need to do anything here\n",
    "        pass\n",
    "\n",
    "\n",
    "    def print_latent_vectors(self):\n",
    "        print \"Users\"\n",
    "        for i in range(self.num_users):\n",
    "            print i,\n",
    "            for d in range(self.latent_d):\n",
    "                print self.users[i, d],\n",
    "            print\n",
    "            \n",
    "        print \"Items\"\n",
    "        for i in range(self.num_items):\n",
    "            print i,\n",
    "            for d in range(self.latent_d):\n",
    "                print self.items[i, d],\n",
    "            print    \n",
    "\n",
    "\n",
    "    def save_latent_vectors(self, prefix):\n",
    "        self.users.dump(prefix + \"%sd_users.pickle\" % self.latent_d)\n",
    "        self.items.dump(prefix + \"%sd_items.pickle\" % self.latent_d)\n",
    "    \n",
    "\n",
    "def fake_ratings(noise=.25):\n",
    "    u = []\n",
    "    v = []\n",
    "    ratings = []\n",
    "    \n",
    "    num_users = 100\n",
    "    num_items = 100\n",
    "    num_ratings = 30\n",
    "    latent_dimension = 10\n",
    "    \n",
    "    # Generate the latent user and item vectors\n",
    "    for i in range(num_users):\n",
    "        u.append(2 * numpy.random.randn(latent_dimension))\n",
    "    for i in range(num_items):\n",
    "        v.append(2 * numpy.random.randn(latent_dimension))\n",
    "        \n",
    "    # Get num_ratings ratings per user.\n",
    "    for i in range(num_users):\n",
    "        items_rated = numpy.random.permutation(num_items)[:num_ratings]\n",
    "\n",
    "        for jj in range(num_ratings):\n",
    "            j = items_rated[jj]\n",
    "            rating = numpy.sum(u[i] * v[j]) + noise * numpy.random.randn()\n",
    "        \n",
    "            ratings.append((i, j, rating))  # thanks sunquiang\n",
    "\n",
    "    return (ratings, u, v)\n",
    "\n",
    "\n",
    "def real_ratings(noise=.25):\n",
    "    u = []\n",
    "    v = []\n",
    "    ratings = []\n",
    "    \n",
    "    num_users = 100\n",
    "    num_items = 100\n",
    "    latent_dimension = 10\n",
    "    \n",
    "    # Generate the latent user and item vectors\n",
    "    for i in range(num_users):\n",
    "        u.append(2 * numpy.random.randn(latent_dimension))\n",
    "    for i in range(num_items):\n",
    "        v.append(2 * numpy.random.randn(latent_dimension))\n",
    "        \n",
    "    # Get ratings per user.\n",
    "    pwd=os.getcwd()\n",
    "    infile = open(os.path.join(pwd, 'data/data.csv'), 'r')\n",
    "    for line in infile.readlines():\n",
    "        f = line.rstrip('\\r\\n').split(\"\\t\")\n",
    "        f = (float(f[0]),float(f[1]),float(f[2]))\n",
    "        ratings.append(f)\n",
    "\n",
    "    return (ratings, u, v)\n",
    "\n",
    "\n",
    "def plot_ratings(ratings):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    for i in range(len(ratings)):\n",
    "        xs.append(ratings[i][1])\n",
    "        ys.append(ratings[i][2])\n",
    "    \n",
    "    pylab.plot(xs, ys, 'bx')\n",
    "    pylab.show()\n",
    "\n",
    "\n",
    "def plot_latent_vectors(U, V):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(121)\n",
    "    cmap = cm.jet\n",
    "    ax.imshow(U, cmap=cmap, interpolation='nearest')\n",
    "    plt.title(\"Users\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.imshow(V, cmap=cmap, interpolation='nearest')\n",
    "    plt.title(\"Items\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_predicted_ratings(U, V):\n",
    "    r_hats = -5 * numpy.ones((U.shape[0] + U.shape[1] + 1, \n",
    "                              V.shape[0] + V.shape[1] + 1))\n",
    "\n",
    "    for i in range(U.shape[0]):\n",
    "        for j in range(U.shape[1]):\n",
    "            r_hats[i + V.shape[1] + 1, j] = U[i, j]\n",
    "\n",
    "    for i in range(V.shape[0]):\n",
    "        for j in range(V.shape[1]):\n",
    "            r_hats[j, i + U.shape[1] + 1] = V[i, j]\n",
    "\n",
    "    for i in range(U.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            r_hats[i + U.shape[1] + 1, j + V.shape[1] + 1] = numpy.dot(U[i], V[j]) / 10\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(r_hats, cmap=cm.gray, interpolation='nearest')\n",
    "    plt.title(\"Predicted Ratings\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #DATASET = 'fake'\n",
    "    DATASET = 'real'\n",
    "\n",
    "    if DATASET == 'fake':\n",
    "        (ratings, true_o, true_d) = fake_ratings()\n",
    "    if DATASET == 'real':\n",
    "        (ratings, true_o, true_d) = real_ratings()\n",
    "    \n",
    "\n",
    "    #plot_ratings(ratings)\n",
    "\n",
    "    pmf = ProbabilisticMatrixFactorization(ratings, latent_d=5)\n",
    "    \n",
    "    liks = []\n",
    "    while (pmf.update()):\n",
    "        lik = pmf.likelihood()\n",
    "        liks.append(lik)\n",
    "        print \"L=\", lik\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(liks)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Log Likelihood\")\n",
    "\n",
    "    plot_latent_vectors(pmf.users, pmf.items)\n",
    "    plot_predicted_ratings(pmf.users, pmf.items)\n",
    "    plt.show()\n",
    "\n",
    "#    pmf.print_latent_vectors()\n",
    "#pmf.save_latent_vectors(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nadine/Desktop/Memoir\n",
      "/home/nadine/Desktop/Memoir/ml-100k\\u.data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pwd=os.getcwd()\n",
    "path=os.path.join(pwd, 'ml-100k\\u.data')\n",
    "print pwd\n",
    "print path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_train_test(name):\n",
    "    \"\"\"Load the train/test sets.\"\"\"\n",
    "    savedir = os.path.join(DATA_DIR, name)\n",
    "    vars = load_np_vars(savedir)\n",
    "    return vars['train'], vars['test']\n",
    "\n",
    "# train, test, name = split_train_test(data)\n",
    "print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
