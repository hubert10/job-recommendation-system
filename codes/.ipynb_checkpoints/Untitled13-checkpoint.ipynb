{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadine/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n",
      "0.18.1\n",
      "1.11.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pandas\n",
    "import numpy\n",
    "print (matplotlib.__version__)\n",
    "print (pandas.__version__)\n",
    "print (numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "#train_data, test_data = cv.train_test_split(df,test_size=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading ratings file:\n",
    "df = pd.read_csv('/home/nadine/Pictures/Memoir/data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = cv.train_test_split(df,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149973, 3), (49991, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>JobId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181744</th>\n",
       "      <td>2133</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150455</th>\n",
       "      <td>1044</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>1324</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89066</th>\n",
       "      <td>217</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49548</th>\n",
       "      <td>432</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47990</th>\n",
       "      <td>2152</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16006</th>\n",
       "      <td>1893</td>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150684</th>\n",
       "      <td>1871</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67144</th>\n",
       "      <td>1760</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>70</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149695</th>\n",
       "      <td>1124</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184650</th>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104821</th>\n",
       "      <td>411</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147639</th>\n",
       "      <td>1432</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50545</th>\n",
       "      <td>1005</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87875</th>\n",
       "      <td>83</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182480</th>\n",
       "      <td>894</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>1707</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171197</th>\n",
       "      <td>703</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184494</th>\n",
       "      <td>626</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166943</th>\n",
       "      <td>1210</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21151</th>\n",
       "      <td>622</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133815</th>\n",
       "      <td>1476</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181113</th>\n",
       "      <td>223</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>1051</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>2213</td>\n",
       "      <td>147</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194498</th>\n",
       "      <td>1673</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191136</th>\n",
       "      <td>697</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97549</th>\n",
       "      <td>1090</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175506</th>\n",
       "      <td>1511</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109944</th>\n",
       "      <td>1273</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96138</th>\n",
       "      <td>1376</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25785</th>\n",
       "      <td>1860</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140707</th>\n",
       "      <td>1525</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125183</th>\n",
       "      <td>1838</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145671</th>\n",
       "      <td>85</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>2369</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95127</th>\n",
       "      <td>1378</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92186</th>\n",
       "      <td>2181</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63050</th>\n",
       "      <td>930</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45142</th>\n",
       "      <td>466</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163166</th>\n",
       "      <td>149</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121941</th>\n",
       "      <td>2353</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100317</th>\n",
       "      <td>791</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51884</th>\n",
       "      <td>604</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59138</th>\n",
       "      <td>2072</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89715</th>\n",
       "      <td>588</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21333</th>\n",
       "      <td>441</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132023</th>\n",
       "      <td>2140</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162650</th>\n",
       "      <td>2120</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78903</th>\n",
       "      <td>1518</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94521</th>\n",
       "      <td>822</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76983</th>\n",
       "      <td>1293</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40034</th>\n",
       "      <td>1632</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111707</th>\n",
       "      <td>291</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162934</th>\n",
       "      <td>2366</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91028</th>\n",
       "      <td>734</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147920</th>\n",
       "      <td>1560</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>932</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190574</th>\n",
       "      <td>1842</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149973 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserId  JobId  Rating\n",
       "181744    2133     87       4\n",
       "150455    1044    102       1\n",
       "5202      1324    128       4\n",
       "89066      217     57       4\n",
       "49548      432     15       3\n",
       "47990     2152    111       3\n",
       "16006     1893    149       4\n",
       "150684    1871     80       3\n",
       "67144     1760     11       2\n",
       "6864        70    134       4\n",
       "149695    1124      7       3\n",
       "184650     136     63       5\n",
       "104821     411      3       4\n",
       "147639    1432     37       5\n",
       "50545     1005     70       5\n",
       "87875       83     66       2\n",
       "182480     894    121       3\n",
       "3339      1707     80       4\n",
       "171197     703      8       4\n",
       "184494     626    114       3\n",
       "166943    1210    101       4\n",
       "21151      622     51       4\n",
       "133815    1476     56       2\n",
       "181113     223     30       2\n",
       "27126     1051     80       3\n",
       "9013      2213    147       5\n",
       "194498    1673     81       5\n",
       "191136     697     14       4\n",
       "97549     1090     23       4\n",
       "175506    1511    134       5\n",
       "...        ...    ...     ...\n",
       "109944    1273     68       1\n",
       "96138     1376    134       4\n",
       "25785     1860    136       2\n",
       "140707    1525    122       3\n",
       "125183    1838     83       5\n",
       "145671      85     74       2\n",
       "7326      2369    128       4\n",
       "95127     1378     92       3\n",
       "92186     2181    129       4\n",
       "63050      930    115       5\n",
       "45142      466     44       4\n",
       "163166     149     26       3\n",
       "121941    2353     32       2\n",
       "100317     791     29       5\n",
       "51884      604     49       5\n",
       "59138     2072     34       5\n",
       "89715      588     17       3\n",
       "21333      441     85       4\n",
       "132023    2140    118       2\n",
       "162650    2120     40       4\n",
       "78903     1518     44       4\n",
       "94521      822     82       3\n",
       "76983     1293     14       3\n",
       "40034     1632     25       3\n",
       "111707     291     34       3\n",
       "162934    2366     62       2\n",
       "91028      734    133       5\n",
       "147920    1560     97       4\n",
       "1037       932     39       3\n",
       "190574    1842     95       1\n",
       "\n",
       "[149973 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference paper: \"Bayesian Probabilistic Matrix Factorization using MCMC\"\n",
    "                 R. Salakhutdinov and A.Mnih.  \n",
    "                 25th International Conference on Machine Learning (ICML-2008) \n",
    "Reference Matlab code: http://www.cs.toronto.edu/~rsalakhu/BPMF.html\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from numpy.linalg import inv, cholesky\n",
    "\n",
    "#from base import Base, DimensionError\n",
    "#from ..util.load_data import load_ml_1m, load_rating_matrix\n",
    "#from ..util.distributions import wishartrand\n",
    "#from ..util.evaluation_metrics import RMSE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Base class of recommendation System\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class NotImplementedError(Exception):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NotImplementedError, self).__init__()\n",
    "\n",
    "\n",
    "class DimensionError(Exception):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DimensionError, self).__init__()\n",
    "\n",
    "\n",
    "class Base(object):\n",
    "\n",
    "    \"\"\"base class of recommendations\"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_errors = []\n",
    "        self.validation_erros = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, iter=1000):\n",
    "        \"\"\"training models\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def suggestions(self, user_id, num=10):\n",
    "        \"\"\"suggest items for given user\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model(self, path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, path):\n",
    "        \"\"\"load saved models\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "#    def __reper__(self):\n",
    "#return self.__class__.__name__()\n",
    "\n",
    "\n",
    "class BayesianMatrixFactorization(Base):\n",
    "\n",
    "    def __init__(self, num_user, num_item, num_feature, train, validation, **params):\n",
    "        super(BayesianMatrixFactorization, self).__init__()\n",
    "\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.num_feature = num_feature\n",
    "        self.train = train\n",
    "        self.validation = validation\n",
    "\n",
    "        self.mean_rating = np.mean(self.train[:, 2])\n",
    "\n",
    "        self.max_rating = params.get('max_rating')\n",
    "        self.min_rating = params.get('min_rating')\n",
    "        if self.max_rating:\n",
    "            self.max_rating = float(self.max_rating)\n",
    "        if self.min_rating:\n",
    "            self.min_rating = float(self.min_rating)\n",
    "\n",
    "        # Hyper Parameter\n",
    "        self.beta = float(params.get('beta', 2.0))\n",
    "        # Inv-Whishart (User features)\n",
    "        self.WI_user = np.eye(num_feature, dtype='float16')\n",
    "        self.beta_user = float(params.get('beta_user', 2.0))\n",
    "        self.df_user = int(params.get('df_user', num_feature))\n",
    "        self.mu_user = np.zeros((num_feature, 1), dtype='float16')\n",
    "\n",
    "        # Inv-Whishart (item features)\n",
    "        self.WI_item = np.eye(num_feature, dtype='float16')\n",
    "        self.beta_item = float(params.get('beta_item', 2.0))\n",
    "        self.df_item = int(params.get('df_item', num_feature))\n",
    "        self.mu_item = np.zeros((num_feature, 1), dtype='float16')\n",
    "\n",
    "        # Latent Variables\n",
    "        self.mu_user = np.zeros((num_feature, 1), dtype='float16')\n",
    "        self.mu_item = np.zeros((num_feature, 1), dtype='float16')\n",
    "\n",
    "        self.alpha_user = np.eye(num_feature, dtype='float16')\n",
    "        self.alpha_item = np.eye(num_feature, dtype='float16')\n",
    "\n",
    "        self.user_features = 0.3 * np.random.rand(num_user, num_feature)\n",
    "        self.item_features = 0.3 * np.random.rand(num_item, num_feature)\n",
    "\n",
    "        self.matrix = load_rating_matrix()\n",
    "\n",
    "    def estimate(self, iterations=100, tolerance=1e-5):\n",
    "        last_rmse = None\n",
    "\n",
    "        # the algorithm will converge, but really slow\n",
    "        # use MF's initialize latent parameter will be better\n",
    "        for iteration in xrange(iterations):\n",
    "            # update item & user parameter\n",
    "            self._update_item_params()\n",
    "            self._update_user_params()\n",
    "\n",
    "            # update item & user_features\n",
    "            self._udpate_item_features()\n",
    "            self._update_user_features()\n",
    "\n",
    "            # compute RMSE\n",
    "            # train errors\n",
    "            train_preds = self.predict(self.train)\n",
    "            train_rmse = RMSE(train_preds, np.float16(self.train[:, 2]))\n",
    "\n",
    "            # validation errors\n",
    "            validation_preds = self.predict(self.validation)\n",
    "            validation_rmse = RMSE(\n",
    "                validation_preds, np.float16(self.validation[:, 2]))\n",
    "            self.train_errors.append(train_rmse)\n",
    "            self.validation_erros.append(validation_rmse)\n",
    "            print \"iterations: %3d, train RMSE: %.6f, validation RMSE: %.6f \" % (iteration + 1, train_rmse, validation_rmse)\n",
    "\n",
    "            # stop if converge\n",
    "            if last_rmse:\n",
    "                if abs(train_rmse - last_rmse) < tolerance:\n",
    "                    break\n",
    "\n",
    "            last_rmse = train_rmse\n",
    "\n",
    "    def predict(self, data):\n",
    "        u_features = self.user_features[data[:, 0], :]\n",
    "        i_features = self.item_features[data[:, 1], :]\n",
    "        preds = np.sum(u_features * i_features, 1) + self.mean_rating\n",
    "\n",
    "        if self.max_rating:\n",
    "            preds[preds > self.max_rating] = self.max_rating\n",
    "\n",
    "        if self.min_rating:\n",
    "            preds[preds < self.min_rating] = self.min_rating\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def _update_item_params(self):\n",
    "        N = self.num_item\n",
    "        X_bar = np.mean(self.item_features, 0)\n",
    "        X_bar = np.reshape(X_bar, (self.num_feature, 1))\n",
    "        # print 'X_bar', X_bar.shape\n",
    "        S_bar = np.cov(self.item_features.T)\n",
    "        # print 'S_bar', S_bar.shape\n",
    "\n",
    "        norm_X_bar = X_bar - self.mu_item\n",
    "        # print 'norm_X_bar', norm_X_bar.shape\n",
    "\n",
    "        WI_post = self.WI_item + N * S_bar + \\\n",
    "            np.dot(norm_X_bar, norm_X_bar.T) * \\\n",
    "            (N * self.beta_item) / (self.beta_item + N)\n",
    "        # print 'WI_post', WI_post.shape\n",
    "\n",
    "        # Not sure why we need this...\n",
    "        WI_post = (WI_post + WI_post.T) / 2.0\n",
    "        df_post = self.df_item + N\n",
    "\n",
    "        # update alpha_item\n",
    "        self.alpha_item = wishartrand(df_post, WI_post)\n",
    "\n",
    "        # update mu_item\n",
    "        mu_temp = (self.beta_item * self.mu_item + N * X_bar) / \\\n",
    "            (self.beta_item + N)\n",
    "        # print \"mu_temp\", mu_temp.shape\n",
    "        lam = cholesky(inv(np.dot(self.beta_item + N, self.alpha_item)))\n",
    "        # print 'lam', lam.shape\n",
    "        self.mu_item = mu_temp + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "        # print 'mu_item', self.mu_item.shape\n",
    "\n",
    "    def _update_user_params(self):\n",
    "        # same as _update_user_params\n",
    "        N = self.num_user\n",
    "        X_bar = np.mean(self.user_features, 0).T\n",
    "        X_bar = np.reshape(X_bar, (self.num_feature, 1))\n",
    "\n",
    "        # print 'X_bar', X_bar.shape\n",
    "        S_bar = np.cov(self.user_features.T)\n",
    "        # print 'S_bar', S_bar.shape\n",
    "\n",
    "        norm_X_bar = X_bar - self.mu_user\n",
    "        # print 'norm_X_bar', norm_X_bar.shape\n",
    "\n",
    "        WI_post = self.WI_user + N * S_bar + \\\n",
    "            np.dot(norm_X_bar, norm_X_bar.T) * \\\n",
    "            (N * self.beta_user) / (self.beta_user + N)\n",
    "        # print 'WI_post', WI_post.shape\n",
    "\n",
    "        # Not sure why we need this...\n",
    "        WI_post = (WI_post + WI_post.T) / 2.0\n",
    "        df_post = self.df_user + N\n",
    "\n",
    "        # update alpha_user\n",
    "        self.alpha_user = wishartrand(df_post, WI_post)\n",
    "\n",
    "        # update mu_item\n",
    "        mu_temp = (self.beta_user * self.mu_user + N * X_bar) / \\\n",
    "            (self.beta_user + N)\n",
    "        # print 'mu_temp', mu_temp.shape\n",
    "        lam = cholesky(inv(np.dot(self.beta_user + N, self.alpha_user)))\n",
    "        # print 'lam', lam.shape\n",
    "        self.mu_user = mu_temp + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "        # print 'mu_user', self.mu_user.shape\n",
    "\n",
    "    def _udpate_item_features(self):\n",
    "        # Gibbs sampling for item features\n",
    "        for item_id in xrange(self.num_item):\n",
    "            vec = self.matrix[:, item_id] > 0.0\n",
    "            # print 'vec', vec.shape\n",
    "            # if vec.shape[0] == 0:\n",
    "            #    continue\n",
    "            features = self.user_features[vec, :]\n",
    "            # print 'features', features.shape\n",
    "            rating = self.matrix[vec, item_id] - self.mean_rating\n",
    "            rating_len = len(rating)\n",
    "            rating = np.reshape(rating, (rating_len, 1))\n",
    "\n",
    "            # print 'rating', rating.shape\n",
    "            covar = inv(\n",
    "                self.alpha_item + self.beta * np.dot(features.T, features))\n",
    "            # print 'covar', covar.shape\n",
    "            lam = cholesky(covar)\n",
    "\n",
    "            temp = self.beta * \\\n",
    "                np.dot(features.T, rating) + np.dot(\n",
    "                    self.alpha_item, self.mu_item)\n",
    "            # print 'temp', temp.shape\n",
    "            mean = np.dot(covar, temp)\n",
    "            # print 'mean', mean.shape\n",
    "            temp_feature = mean + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "            temp_feature = np.reshape(temp_feature, (self.num_feature,))\n",
    "            self.user_features[item_id, :] = temp_feature\n",
    "\n",
    "    def _update_user_features(self):\n",
    "        self.matrix = self.matrix.T\n",
    "        # Gibbs sampling for user features\n",
    "        for user_id in xrange(self.num_user):\n",
    "            vec = self.matrix[:, user_id] > 0.0\n",
    "            # print len(vec)\n",
    "            # if vec.shape[0] == 0:\n",
    "            #    continue\n",
    "            # print \"item_feature\", self.item_features.shape\n",
    "            features = self.item_features[vec, :]\n",
    "            rating = self.matrix[vec, user_id] - self.mean_rating\n",
    "            rating_len = len(rating)\n",
    "            rating = np.reshape(rating, (rating_len, 1))\n",
    "\n",
    "            # print 'rating', rating.shape\n",
    "            covar = inv(\n",
    "                self.alpha_user + self.beta * np.dot(features.T, features))\n",
    "            lam = cholesky(covar)\n",
    "            temp = self.beta * \\\n",
    "                np.dot(features.T, rating) + np.dot(\n",
    "                    self.alpha_user, self.mu_user)\n",
    "            mean = np.dot(covar, temp)\n",
    "            # print 'mean', mean.shape\n",
    "            temp_feature = mean + np.dot(lam, rand.randn(self.num_feature, 1))\n",
    "            temp_feature = np.reshape(temp_feature, (self.num_feature,))\n",
    "            self.user_features[user_id, :] = temp_feature\n",
    "\n",
    "        # transpose back\n",
    "        self.matrix = self.matrix.T\n",
    "\n",
    "    def suggestions(self, user_id, num=10):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def save_model(self):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def load_model(self):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def load_features(self, path):\n",
    "        import cPickle\n",
    "        import gzip\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            self._user_features = cPickle.load(f)\n",
    "            self._item_features = cPickle.load(f)\n",
    "            num_user, num_feature_u = self._user_features.shape\n",
    "            num_item, num_feature_i = self._item_features.shape\n",
    "\n",
    "            if num_feature_i != num_feature_u:\n",
    "                raise DimensionError()\n",
    "            self._num_feature = num_feature_i\n",
    "\n",
    "        return self\n",
    "\n",
    "    def save_features(self, path):\n",
    "        import cPickle\n",
    "        import gzip\n",
    "        with gzip.open(path, 'wb') as f:\n",
    "            cPickle.dump(\n",
    "                self._user_features, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "            cPickle.dump(\n",
    "                self._item_features, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def example():\n",
    "    \"\"\"simple test and performance measure\n",
    "    \"\"\"\n",
    "    num_user, num_item, ratings = load_ml_1m()\n",
    "    # suffle_data\n",
    "    np.random.shuffle(ratings)\n",
    "\n",
    "    # split data to training & validation\n",
    "    train_pct = 0.9\n",
    "    train_size = int(train_pct * len(ratings))\n",
    "    train = ratings[:train_size]\n",
    "    validation = ratings[train_size:]\n",
    "\n",
    "    # params\n",
    "    num_feature = 10\n",
    "    bmf_model = BayesianMatrixFactorization(\n",
    "        num_user, num_item, num_feature, train, validation, max_rating=5, min_rating=1)\n",
    "\n",
    "    start_time = time.clock()\n",
    "    bmf_model.estimate(5)\n",
    "    end_time = time.clock()\n",
    "    print \"time spend = %.3f\" % (end_time - start_time)\n",
    "\n",
    "    return bmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def RMSE(estimation, truth):\n",
    "    \"\"\"Root Mean Square Error\"\"\"\n",
    "\n",
    "    num_sample = len(estimation)\n",
    "\n",
    "    # sum square error \n",
    "    sse = np.sum(np.square(truth - estimation))\n",
    "    return np.sqrt(np.divide(sse, num_sample - 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data set\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "\n",
    "def build_ml_1m():\n",
    "    \"\"\"\n",
    "    build movie lens 1M ratings from original ml_1m rating file.\n",
    "    need to download and put ml_1m data in /data folder first.\n",
    "    Source: http://www.grouplens.org/\n",
    "    \"\"\"\n",
    "    num_user = 6040\n",
    "    num_item = 3952\n",
    "    print(\"\\nloadind movie lens 1M data\")\n",
    "    with open(\"data/ratings.dat\", \"rb\") as f:\n",
    "        iter_lines = iter(f)\n",
    "        ratings = []\n",
    "        for line_num, line in enumerate(iter_lines):\n",
    "            # format (user_id, item_id, rating)\n",
    "            line = line.split('::')[:3]\n",
    "            line = [int(l) for l in line]\n",
    "            ratings.append(line)\n",
    "\n",
    "            if line_num % 100000 == 0:\n",
    "                print line_num\n",
    "\n",
    "    ratings = np.array(ratings)\n",
    "\n",
    "    # shift user_id & movie_id by 1. let user_id & movie_id start from 0\n",
    "    ratings[:, (0, 1)] = ratings[:, (0, 1)] - 1\n",
    "    print \"max user id\", max(ratings[:, 0])\n",
    "    print \"max item id\", max(ratings[:, 1])\n",
    "    return num_user, num_item, ratings\n",
    "\n",
    "\n",
    "def load_ml_1m():\n",
    "    \"\"\"load Movie Lens 1M ratings from saved gzip file\"\"\"\n",
    "    import gzip\n",
    "    import csv\n",
    "    import cPickle\n",
    "\n",
    "    file_path = 'data/data.csv'\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        print \"load ratings from: %s\" % file_path\n",
    "        num_user = cPickle.load(f)\n",
    "        num_item = cPickle.load(f)\n",
    "        ratings = cPickle.load(f)\n",
    "\n",
    "        return num_user, num_item, ratings\n",
    "\n",
    "\n",
    "def build_rating_matrix(num_user, num_item, ratings):\n",
    "    \"\"\"\n",
    "    build dense ratings matrix from original ml_1m rating file.\n",
    "    need to download and put ml_1m data in /data folder first.\n",
    "    Source: http://www.grouplens.org/\n",
    "    \"\"\"\n",
    "\n",
    "    print '\\nbuild matrix'\n",
    "    # sparse matrix\n",
    "    #matrix = sparse.lil_matrix((num_user, num_item))\n",
    "    # dense matrix\n",
    "    matrix = np.zeros((num_user, num_item), dtype='int8')\n",
    "    for item_id in xrange(num_item):\n",
    "        data = ratings[ratings[:, 1] == item_id]\n",
    "        if data.shape[0] > 0:\n",
    "            matrix[data[:, 0], item_id] = data[:, 2]\n",
    "\n",
    "        if item_id % 1000 == 0:\n",
    "            print item_id\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def load_rating_matrix():\n",
    "    \"\"\"\n",
    "    load Movie Lens 1M ratings from saved gzip file\n",
    "    Format is numpy dense matrix\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    import cPickle\n",
    "\n",
    "    file_path = 'data/rating_matrix.gz'\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        print \"load ratings matrix from: %s\" % file_path\n",
    "        return cPickle.load(f)\n",
    "\n",
    "\n",
    "def build_sparse_matrix(num_user, num_item, ratings):\n",
    "    # TODO: have not tested it yet. will test after algorithm support sparse\n",
    "    # matrix\n",
    "    print '\\nbuild sparse matrix'\n",
    "    # sparse matrix\n",
    "    matrix = sparse.lil_matrix((num_user, num_item))\n",
    "    for item_id in xrange(num_item):\n",
    "        data = ratings[ratings[:, 1] == item_id]\n",
    "        if data.shape[0] > 0:\n",
    "            # for sparse matrix\n",
    "            matrix[data[:, 0], item_id] = np.array([data[:, 2]]).T\n",
    "\n",
    "        if item_id % 1000 == 0:\n",
    "            print item_id\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-35070a9a5446>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-35070a9a5446>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    np.random.shuffle(data_train)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    # load MovieLens data\n",
    "#    num_user, num_item, ratings = load_ml_1m()\n",
    "    import numpy as np\n",
    "    np.random.shuffle(data_train)\n",
    "\n",
    "    # set feature numbers\n",
    "    num_feature = 10\n",
    "\n",
    "    # set max_iterations\n",
    "    max_iter = 20\n",
    "\n",
    "    # split data to training & testing\n",
    "    train_pct = 0.9\n",
    "    train_size = int(train_pct * len(self.ratings))\n",
    "    train = ratings[:train_size]\n",
    "    validation = ratings[train_size:]\n",
    "\n",
    "    # models\n",
    "    rec = MatrixFactorization(num_user, num_item, num_feature, train, validation, max_rating=5, min_rating=1)\n",
    "\n",
    "    # fitting\n",
    "    rec.estimate(max_iter)\n",
    "\n",
    "    # results\n",
    "    train_preds = rec.predict(train)\n",
    "    train_rmse = RMSE(validation_preds, np.float16(train[:, 2]))\n",
    "    validation_preds = rec.predict(validation)\n",
    "    validation_rmse = RMSE(validation_preds, np.float16(validation[:, 2]))\n",
    "\n",
    "print \"train RMSE: %.6f, validation RMSE: %.6f \" % (train_rmse, validation_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
